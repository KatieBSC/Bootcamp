{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "housing_data = pd.read_csv(\"housing.csv\")\n",
    "# Fill NA\n",
    "housing_data['total_bedrooms'] = housing_data['total_bedrooms'].fillna(\n",
    "    (housing_data['total_bedrooms'].sum())/len(housing_data['total_bedrooms']))\n",
    "# Clean targets\n",
    "housing_data = housing_data[housing_data['median_house_value'] < (housing_data['median_house_value'].max())]\n",
    "# Encode categories and replace columns\n",
    "housing_cat = housing_data['ocean_proximity']\n",
    "housing_cat_encoded,housing_categories = housing_cat.factorize()\n",
    "encoder = OneHotEncoder()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\n",
    "housing_cat_1hot = housing_cat_1hot.toarray()\n",
    "ocean_proximity_cat_1hot = pd.DataFrame(housing_cat_1hot)\n",
    "ocean_proximity_cat_1hot = ocean_proximity_cat_1hot.rename(columns=\n",
    "                            {0: 'NEAR BAY', 1: '<1H OCEAN', 2:'INLAND', 3:'NEAR OCEAN', 4:'ISLAND'})\n",
    "housing_data = housing_data.reset_index(drop=True)\n",
    "housing_data = pd.concat([housing_data, ocean_proximity_cat_1hot], axis=1, sort=False)\n",
    "housing_data = housing_data.drop('ocean_proximity',axis=1)\n",
    "# Train test split\n",
    "housing_train, housing_test = train_test_split(housing_data, test_size=0.33, random_state=11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs to be edited/removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree :\n",
    "    def __init__ (self,X_train,y_train,X_test,y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def fit_tree (self,depth):\n",
    "        dTree = DecisionTreeRegressor(max_depth=depth)\n",
    "        return dTree.fit(self.X_train,self.y_train)\n",
    "    \n",
    "    def predict_tree (self,depth):\n",
    "        pred = self.fit_tree(depth).predict(self.X_test)\n",
    "        return pred\n",
    "    \n",
    "    def evaluate_tree (self,depth):\n",
    "        mse = mean_squared_error(self.y_test,self.predict_tree(depth))\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression:\n",
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13182,  8767,  4399,  4368,  4415,  3114,  1301])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 2\n",
    "X_train = housing_train[['latitude','median_income']]\n",
    "y_train = housing_train[['median_house_value']]\n",
    "\n",
    "my_tree = DecisionTreeRegressor(max_depth=depth)\n",
    "my_tree.fit(X_train,y_train)\n",
    "#pred = my_tree.predict(X_train)\n",
    "\n",
    "tree_array = [my_tree]\n",
    "num_nodes = my_tree.tree_.capacity\n",
    "index = 0\n",
    "alpha = 0\n",
    "k = 1\n",
    "\n",
    "tree_array[0].tree_.n_node_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48082470140780.516\n",
      "29038658908520.07\n"
     ]
    }
   ],
   "source": [
    "def leaf_impurity(tree, index):\n",
    "    if tree.tree_.children_left[index] == _tree.TREE_LEAF:   \n",
    "            return (tree.tree_.n_node_samples[index] *  tree.tree_.impurity[index])\n",
    "        \n",
    "    \n",
    "subtree_1 = leaf_impurity(tree_array[0],2)+leaf_impurity(tree_array[0],3)\n",
    "subtree_4 = leaf_impurity(tree_array[0],5)+leaf_impurity(tree_array[0],6)\n",
    "print(subtree_1)\n",
    "print(subtree_4)\n",
    "#\n",
    "#if tree.tree_.children_left[index] != _tree.TREE_LEAF:\n",
    "#            impurity_left, leafs_left = leaf_impurity(tree, tree.tree_.children_left[index])\n",
    "#            impurity_right, leafs_right = leaf_impurity(tree, tree.tree_.children_right[index])\n",
    "#            print ('Leaf ' + str(index) + ' Impurity: ' + str(impurity_left+impurity_right), \n",
    "#                   'composed of ' + str(leafs_left+leafs_right) + ' leaves')                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children left side: [ 1  2 -1 -1  5 -1 -1]\n",
      "Tree n node samples: [13182  8767  4399  4368  4415  3114  1301]\n",
      "Tree Impurity: [9.49045916e+09 6.31294054e+09 4.56808725e+09 6.40738423e+09\n",
      " 8.27535008e+09 6.57003518e+09 6.59459596e+09]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"Children left side: \" + str(tree_array[0].tree_.children_left)\n",
    "print \"Tree n node samples: \" + str(tree_array[0].tree_.n_node_samples) \n",
    "print \"Tree Impurity: \" + str(tree_array[0].tree_.impurity)\n",
    "\n",
    "        \n",
    "\n",
    "#(77121129049300.6, 4)\n",
    "#(48082470140780.516, 2)\n",
    "#(29038658908520.07, 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IDX: ', 0, 'NI: ', 125103232624977.56, 'STI: ', 77121129049300.6, 'STL: ', 4)\n",
      "('IDX: ', 1, 'NI: ', 55345549705438.414, 'STI: ', 48082470140780.516, 'STL: ', 2)\n",
      "('IDX: ', 4, 'NI: ', 36535670619936.86, 'STI: ', 29038658908520.07, 'STL: ', 2)\n",
      "('IDX: ', 0, 'NI: ', 125103232624977.56, 'STI: ', 84384208613958.48, 'STL: ', 3)\n",
      "('IDX: ', 4, 'NI: ', 36535670619936.86, 'STI: ', 29038658908520.07, 'STL: ', 2)\n",
      "('IDX: ', 0, 'NI: ', 125103232624977.56, 'STI: ', 91881220325375.28, 'STL: ', 2)\n"
     ]
    }
   ],
   "source": [
    "while num_nodes > 1:\n",
    "    tree_array.append(copy.deepcopy(tree_array[k - 1]))\n",
    "\n",
    "    min_node_idx, min_gk = determine_alpha(tree_array[k].tree_)\n",
    "\n",
    "    prune(tree_array[k].tree_, min_node_idx)\n",
    "\n",
    "    num_nodes = sum(1 * (tree_array[k].tree_.n_node_samples != 0))\n",
    "\n",
    "    k += 1\n",
    "\n",
    "\n",
    "    if False:\n",
    "        for k in range(0,len(tree_array)):\n",
    "            export_graphviz(tree_array[k], out_file='tree' + str(k) + '.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_impurity(tree, index):\n",
    "    \"\"\"\n",
    "    Calc_impurity is a recursive function for calculating the absolute impurity of any subtree.\n",
    "    The absolute impurity is calculated by the impurity of every leaf-node scaled with the number of samples per node.\n",
    "    @:param tree: sk-learn tree object\n",
    "    @:param index: the index of the root node of the subtree\n",
    "    @:returns impurity and leaf count of subtree\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"index: \", index, \" impurity: \", d_tree.tree_.n_node_samples[index] * tree.impurity[index] / 10000000)\n",
    "    # wenn es 'children' besuche die 'children'\n",
    "    if tree.children_left[index] != _tree.TREE_LEAF:\n",
    "        impurity_left, leafs_left = _calc_impurity(tree, tree.children_left[index])\n",
    "        impurity_right, leafs_right = _calc_impurity(tree, tree.children_right[index])\n",
    "\n",
    "        return impurity_left + impurity_right, leafs_left + leafs_right\n",
    "\n",
    "    # wenn es keine 'children' gibt bin ich ein leaf Knoten\n",
    "    else:\n",
    "        # print(\"index: \", index, \" cost: \", d_tree.tree_.n_node_samples[index] * tree.impurity[index]/10000000)\n",
    "        return tree.n_node_samples[index] * tree.impurity[index], 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77121129049300.6, 4)\n",
      "(48082470140780.516, 2)\n",
      "(20095015826943.496, 1)\n",
      "(27987454313837.02, 1)\n",
      "(29038658908520.07, 2)\n",
      "(20459089565783.688, 1)\n",
      "(8579569342736.382, 1)\n"
     ]
    }
   ],
   "source": [
    "print _calc_impurity(tree=my_tree.tree_,index=0)\n",
    "print _calc_impurity(tree=my_tree.tree_,index=1)\n",
    "print _calc_impurity(tree=my_tree.tree_,index=2)\n",
    "print _calc_impurity(tree=my_tree.tree_,index=3)\n",
    "print _calc_impurity(tree=my_tree.tree_,index=4)\n",
    "print _calc_impurity(tree=my_tree.tree_,index=5)\n",
    "print _calc_impurity(tree=my_tree.tree_,index=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def prune(inner_tree, index):\n",
    "    \"\"\"\n",
    "    The given tree object is modified to resemble a version pruned at index\n",
    "    @:param inner_tree: sk-learn tree object\n",
    "    @:param index: the index of the node at which inner_tree is pruned\n",
    "    \"\"\"\n",
    "\n",
    "    # wenn es 'children' gibt besuche ich die 'children'\n",
    "    if inner_tree.children_left[index] != _tree.TREE_LEAF:\n",
    "        prune(inner_tree, inner_tree.children_left[index])\n",
    "\n",
    "        prune(inner_tree, inner_tree.children_right[index])\n",
    "\n",
    "        # set node to leaf\n",
    "        idx_left = inner_tree.children_left[index]\n",
    "        idx_right = inner_tree.children_right[index]\n",
    "\n",
    "        inner_tree.children_left[index] = _tree.TREE_LEAF\n",
    "        inner_tree.children_right[index] = _tree.TREE_LEAF\n",
    "\n",
    "        inner_tree.n_node_samples[idx_left] = 0\n",
    "        inner_tree.n_node_samples[idx_right] = 0\n",
    "\n",
    "        inner_tree.impurity[idx_left] = 0\n",
    "        inner_tree.impurity[idx_right] = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        # wenn es keine 'children' gibt kann ich prunen\n",
    "        inner_tree.n_node_samples[index] = 0\n",
    "\n",
    "\n",
    "def determine_alpha(tree):\n",
    "    \"\"\"\n",
    "    Given a regression tree, the relevant penalty scalars gk are determined for pruning. Every\n",
    "    inner node of the tree is visit to evaluate the penalty scalar gk that would make pruning in each node reasonable.\n",
    "    The minimum gk is returned\n",
    "    @:param tree: sk-learn tree object\n",
    "    @:returns the index and corresponding values of the minimal gk found in the tree (alpha)\n",
    "    \"\"\"\n",
    "    min_gk = sys.maxsize\n",
    "    min_node_idx = tree.node_count\n",
    "\n",
    "    # traverse all inner nodes in to find min_gk\n",
    "    for node_idx in range(tree.node_count):\n",
    "        # if node is a leaf node, skip node\n",
    "        if tree.children_left[node_idx] == _tree.TREE_LEAF:\n",
    "            continue\n",
    "\n",
    "        # inner node\n",
    "        node_impurity = tree.n_node_samples[node_idx] * tree.impurity[node_idx]\n",
    "        subtree_impurity, subtree_leafs = _calc_impurity(tree, node_idx)\n",
    "\n",
    "        print('IDX: ', node_idx, 'NI: ', node_impurity, 'STI: ', subtree_impurity, 'STL: ', subtree_leafs)\n",
    "\n",
    "        gk = (node_impurity - subtree_impurity) / (subtree_leafs - 1.)\n",
    "\n",
    "        if gk < min_gk:\n",
    "            min_node_idx = node_idx\n",
    "            min_gk = gk\n",
    "\n",
    "    return min_node_idx, min_gk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IDX: ', 0, 'NI: ', 27483.198193687535, 'STI: ', 23353.654436952438, 'STL: ', 4)\n",
      "('IDX: ', 1, 'NI: ', 23794.915979009485, 'STI: ', 21794.09704806807, 'STL: ', 2)\n",
      "('IDX: ', 4, 'NI: ', 1823.7866455056505, 'STI: ', 1559.5573888843676, 'STL: ', 2)\n",
      "('IDX: ', 0, 'NI: ', 27483.198193687535, 'STI: ', 23617.88369357372, 'STL: ', 3)\n",
      "('IDX: ', 1, 'NI: ', 23794.915979009485, 'STI: ', 21794.09704806807, 'STL: ', 2)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#from classifier.prune import determine_alpha, prune\n",
    "\n",
    "sns.set()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "    input_features = data[['latitude', 'longitude']]\n",
    "    target = data['median_house_value'] / 100000\n",
    "\n",
    "    d_tree = DecisionTreeRegressor(max_depth=2)\n",
    "    d_tree.fit(input_features, target)\n",
    "\n",
    "    tree_array = [d_tree]\n",
    "\n",
    "    num_nodes = d_tree.tree_.capacity\n",
    "    index = 0\n",
    "    alpha = 0\n",
    "    k = 1\n",
    "\n",
    "    while num_nodes > 1:\n",
    "        tree_array.append(copy.deepcopy(tree_array[k - 1]))\n",
    "\n",
    "        min_node_idx, min_gk = determine_alpha(tree_array[k].tree_)\n",
    "\n",
    "        prune(tree_array[k].tree_, min_node_idx)\n",
    "\n",
    "        num_nodes = sum(1 * (tree_array[k].tree_.n_node_samples != 0))\n",
    "\n",
    "        k += 1\n",
    "\n",
    "\n",
    "    if False:\n",
    "        for k in range(0,len(tree_array)):\n",
    "            export_graphviz(tree_array[k], out_file='tree' + str(k) + '.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
